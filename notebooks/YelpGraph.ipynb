{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch a TigerGraph Developer instance on AWS \n",
    "Use the following command in a shell to connect to it \n",
    "\n",
    "`ssh -L14240:localhost:14240 -L 8888:localhost:8888 -i your_aws_key.pem ubuntu@your-server-ip`\n",
    "\n",
    "Inside the server clone the autoTigerGraph repository\n",
    "\n",
    "`git clone https://github.com/yaniv256/autoTigerGraph`\n",
    "\n",
    "Run `jupyter notebook` on the server and open this notebook from the `notebooks` directory \n",
    "\n",
    "Make sure that the GSQL server is running with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[   Info] \u001b[0m\u001b[32mStarting\u001b[0m EXE\n",
      "\u001b[34m[   Info] \u001b[0m\u001b[32mStarting\u001b[0m CTRL\n",
      "\u001b[34m[   Info] \u001b[0m\u001b[32mStarting\u001b[0m ZK ETCD DICT KAFKA ADMIN GSE NGINX GPE RESTPP KAFKASTRM-LL KAFKACONN TS3SERV GSQL TS3 IFM GUI\n"
     ]
    }
   ],
   "source": [
    "!gadmin start all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the connection by clicking on the link below. It should open TigerStudio in a browser window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:14240\n"
     ]
    }
   ],
   "source": [
    "server = 'http://localhost'\n",
    "print(server+':14240')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup working enviroment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (1.5.6)\n",
      "Requirement already satisfied: ijson in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (3.1.post0)\n",
      "Requirement already satisfied: pyTigerGraph in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (0.0.6.2)\n",
      "Requirement already satisfied: python-slugify in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (4.44.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (2020.4.5.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: validators in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pyTigerGraph) (0.15.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->kaggle) (2.9)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from validators->pyTigerGraph) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle ijson pyTigerGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install autoTigerGraph from local respository\n",
    "You'll need to restart the kernal after this one (keyboard shortcut 0,0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/ubuntu/autoTigerGraph\n",
      "Installing collected packages: autoTigerGraph\n",
      "  Attempting uninstall: autoTigerGraph\n",
      "    Found existing installation: autoTigerGraph 0.0.1\n",
      "    Uninstalling autoTigerGraph-0.0.1:\n",
      "      Successfully uninstalled autoTigerGraph-0.0.1\n",
      "  Running setup.py develop for autoTigerGraph\n",
      "Successfully installed autoTigerGraph\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Yelp Dataset from Kaggle\n",
    "\n",
    "see https://www.kaggle.com/docs/api on how to obtain a kaggle token. Run the next cell and upload your token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8946c0271d234b74946069aa86a27f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "upload = FileUpload()\n",
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w+b\") as i:\n",
    "    i.write(upload.data[0])\n",
    "    \n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yelp-dataset.zip to /home/ubuntu/autoTigerGraph/notebooks\n",
      "100%|█████████████████████████████████████▉| 4.48G/4.48G [01:30<00:00, 82.9MB/s]\n",
      "100%|██████████████████████████████████████| 4.48G/4.48G [01:30<00:00, 53.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download yelp-dataset/yelp-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  yelp-dataset.zip\n",
      "  inflating: Dataset_Agreement.pdf   \n",
      "  inflating: yelp_academic_dataset_business.json  \n",
      "  inflating: yelp_academic_dataset_checkin.json  \n",
      "  inflating: yelp_academic_dataset_review.json  \n",
      "  inflating: yelp_academic_dataset_tip.json  \n",
      "  inflating: yelp_academic_dataset_user.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o yelp-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14911464\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      41776 Mar 26 01:18 Dataset_Agreement.pdf\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      35460 Jul  2 19:44 YelpGraph.ipynb\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 4809540040 Jul  2 19:41 \u001b[0m\u001b[01;31myelp-dataset.zip\u001b[0m\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  152898689 Mar 26 01:18 yelp_academic_dataset_business.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  449663480 Mar 26 01:18 yelp_academic_dataset_checkin.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 6325565224 Mar 26 01:19 yelp_academic_dataset_review.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  263489322 Mar 26 01:31 yelp_academic_dataset_tip.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3268069927 Mar 26 01:32 yelp_academic_dataset_user.json\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm yelp-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_academic_dataset_business.json\r\n",
      "{\"business_id\":\"f9NumwFMBDn751xgFiRbNA\",\"name\":\"The Range At Lake Norman\",\"address\":\"10913 Bailey Rd\",\"city\":\"Cornelius\",\"state\":\"NC\",\"postal_code\":\"28031\",\"latitude\":35.4627242,\"longitude\":-80.8526119,\"stars\":3.5,\"review_count\":36,\"is_open\":1,\"attributes\":{\"BusinessAcceptsCreditCards\":\"True\",\"BikeParking\":\"True\",\"GoodForKids\":\"False\",\"BusinessParking\":\"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\",\"ByAppointmentOnly\":\"False\",\"RestaurantsPriceRange2\":\"3\"},\"categories\":\"Active Life, Gun\\/Rifle Ranges, Guns & Ammo, Shopping\",\"hours\":{\"Monday\":\"10:0-18:0\",\"Tuesday\":\"11:0-20:0\",\"Wednesday\":\"10:0-18:0\",\"Thursday\":\"11:0-20:0\",\"Friday\":\"11:0-20:0\",\"Saturday\":\"11:0-20:0\",\"Sunday\":\"13:0-18:0\"}}\r\n",
      "\r\n",
      "yelp_academic_dataset_checkin.json\r\n",
      "{\"business_id\":\"--1UhMGODdWsrMastO9DZw\",\"date\":\"2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016-10-15 02:45:18, 2016-11-18 01:54:50, 2017-04-20 18:39:06, 2017-05-03 17:58:02, 2019-03-19 22:04:48\"}\r\n",
      "\r\n",
      "yelp_academic_dataset_review.json\r\n",
      "{\"review_id\":\"xQY8N_XvtGbearJ5X4QryQ\",\"user_id\":\"OwjRMXRC0KyPrIlcjaXeFQ\",\"business_id\":\"-MhfebM0QIsKt87iDN-FNw\",\"stars\":2.0,\"useful\":5,\"funny\":0,\"cool\":0,\"text\":\"As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\n\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It's what real estate agents would call \\\"cozy\\\" or \\\"charming\\\" - basically any euphemism for small.\\n\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\n\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\n* it's not kid friendly at all. Seriously, don't bring them.\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \\\"just look around\\\" and \\\"do whatever.\\\" \\n\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.\",\"date\":\"2015-04-15 05:21:16\"}\r\n",
      "\r\n",
      "yelp_academic_dataset_tip.json\r\n",
      "{\"user_id\":\"hf27xTME3EiCp6NL6VtWZQ\",\"business_id\":\"UYX5zL_Xj9WEc_Wp-FrqHw\",\"text\":\"Here for a quick mtg\",\"date\":\"2013-11-26 18:20:08\",\"compliment_count\":0}\r\n",
      "\r\n",
      "yelp_academic_dataset_user.json\r\n",
      "{\"user_id\":\"ntlvfPzc8eglqvk92iDIAw\",\"name\":\"Rafael\",\"review_count\":553,\"yelping_since\":\"2007-07-06 03:27:11\",\"useful\":628,\"funny\":225,\"cool\":227,\"elite\":\"\",\"friends\":\"oeMvJh94PiGQnx_6GlndPQ, wm1z1PaJKvHgSDRKfwhfDg, IkRib6Xs91PPW7pon7VVig, A8Aq8f0-XvLBcyMk2GJdJQ, eEZM1kogR7eL4GOBZyPvBA, e1o1LN7ez5ckCpQeAab4iw, _HrJVzFaRFUhPva8cwBjpQ, pZeGZGzX-ROT_D5lam5uNg, 0S6EI51ej5J7dgYz3-O0lA, woDt8raW-AorxQM_tIE2eA, hWUnSE5gKXNe7bDc8uAG9A, c_3LDSO2RHwZ94_Q6j_O7w, -uv1wDiaplY6eXXS0VwQiA, QFjqxXn3acDC7hckFGUKMg, ErOqapICmHPTN8YobZIcfQ, mJLRvqLOKhqEdkgt9iEaCQ, VKX7jlScJSA-ja5hYRw12Q, ijIC9w5PRcj3dWVlanjZeg, CIZGlEw-Bp0rmkP8M6yQ9Q, OC6fT5WZ8EU7tEVJ3bzPBQ, UZSDGTDpycDzrlfUlyw2dQ, deL6e_z9xqZTIODKqnvRXQ, 5mG2ENw2PylIWElqHSMGqg, Uh5Kug2fvDd51RYmsNZkGg, 4dI4uoShugD9z84fYupelQ, EQpFHqGT9Tk6YSwORTtwpg, o4EGL2-ICGmRJzJ3GxB-vw, s8gK7sdVzJcYKcPv2dkZXw, vOYVZgb_GVe-kdtjQwSUHw, wBbjgHsrKr7BsPBrQwJf2w, p59u2EC_qcmCmLeX1jCi5Q, VSAZI1eHDrOPRWMK4Q2DIQ, efMfeI_dkhpeGykaRJqxfQ, x6qYcQ8_i0mMDzSLsFCbZg, K_zSmtNGw1fu-vmxyTVfCQ, 5IM6YPQCK-NABkXmHhlRGQ, U_w8ZMD26vnkeeS1sD7s4Q, AbfS_oXF8H6HJb5jFqhrLw, hbcjX4_D4KIfonNnwrH-cg, UKf66_MPz0zHCP70mF6p1g, hK2gYbxZRTqcqlSiQQcrtQ, 2Q45w_Twx_T9dXqlE16xtQ, BwRn8qcKSeA77HLaOTbfiQ, jouOn4VS_DtFPtMR2w8VDA, ESteyJabbfvqas6CEDs3pQ\",\"fans\":14,\"average_stars\":3.57,\"compliment_hot\":3,\"compliment_more\":2,\"compliment_profile\":1,\"compliment_cute\":0,\"compliment_list\":1,\"compliment_note\":11,\"compliment_plain\":15,\"compliment_cool\":22,\"compliment_funny\":22,\"compliment_writer\":10,\"compliment_photos\":0}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash -c 'for i in *.json; do echo $i; head -1 $i; echo; done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make changes if you want to autoTigerGraph.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../autoTigerGraph/autoTigerGraph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../autoTigerGraph/autoTigerGraph.py\n",
    "import ijson\n",
    "\n",
    "print('Loaded local dev copy of autoTigerGraph!')\n",
    "\n",
    "def get_first(filename):\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        objects = ijson.items(f, '', multiple_values=True, use_float=True)\n",
    "        first  = objects.__next__()\n",
    "        fields = list(zip(range(len(first)), \n",
    "                        list(first.keys()), \n",
    "                        [type(value).__name__ for value in first.values()]))\n",
    "\n",
    "    return first, fields\n",
    "\n",
    "\n",
    "def vertex_from_json(json_object, vertex_name, fields=None):\n",
    "\n",
    "    if fields == None:\n",
    "        fields = json_object.keys()\n",
    "    \n",
    "    type_translate = {'str': 'STRING', 'dict': 'STRING', 'float': 'DOUBLE', \n",
    "                      'bool': 'BOOL', 'int': 'INT'}\n",
    "\n",
    "    gsql_cmd  = 'CREATE VERTEX ' + vertex_name + ' (PRIMARY_ID ' \n",
    "    \n",
    "    for field in fields:\n",
    "\n",
    "        if field == 'date':\n",
    "            gsql_cmd += 'date_time' + ' '\n",
    "            gsql_cmd += 'DATETIME'\n",
    "        else:    \n",
    "            gsql_cmd += field + ' '\n",
    "            gsql_cmd += type_translate[type(json_object[field]).__name__]\n",
    "    \n",
    "        gsql_cmd += ', '\n",
    "\n",
    "    return gsql_cmd[:-2] + ')'\n",
    "\n",
    "def problem_fields_to_str(json_object):\n",
    "\n",
    "    for key, value in json_object.items():\n",
    "        if isinstance(value, dict) or value == None:\n",
    "            json_object[key] = str(value)\n",
    "        if key == 'date':\n",
    "            json_object.pop(key)\n",
    "            json_object['date_time'] = value\n",
    "\n",
    "    return json_object\n",
    "\n",
    "\n",
    "def upsert_json_vertices(filename, conn, vertex_name, primary_id, batch_size, max_verts):\n",
    "\n",
    "    ids = ['']*batch_size\n",
    "    bodies = ['']*batch_size\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        objects = ijson.items(f, '', multiple_values=True, use_float=True)\n",
    "\n",
    "        i = 0\n",
    "        count = 0\n",
    "        for json_object in objects:\n",
    "\n",
    "            if json_object:\n",
    "                ids[i]=json_object.pop(primary_id)\n",
    "                bodies[i]=problem_fields_to_str(json_object)\n",
    "                count += 1\n",
    "                i += 1\n",
    "                if count >= max_verts:\n",
    "                    break\n",
    "                if i%batch_size == 0:\n",
    "                    conn.upsertVertices(vertex_name, list(zip(ids, bodies)))\n",
    "                    i = 0\n",
    "\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    conn.upsertVertices(vertex_name, list(zip(ids[:i], bodies[:i])))\n",
    "\n",
    "    return count\n",
    "\n",
    "def upsert_json_edges(filename, conn, from_name, from_field, edge_name, \n",
    "                      to_name, to_field, batch_size, max_edges, split_string=', '):\n",
    "\n",
    "    froms = ['']*batch_size\n",
    "    tos = ['']*batch_size\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        objects = ijson.items(f, '', multiple_values=True, use_float=True)\n",
    "\n",
    "        i = 0\n",
    "        count = 0\n",
    "        for json_object in objects:\n",
    "\n",
    "            if json_object:\n",
    "                \n",
    "                json_froms = json_object[from_field].split(split_string)\n",
    "                jsom_tos = json_object[to_field].split(split_string)\n",
    "                \n",
    "                if len(json_from) > 1:\n",
    "                    json_to *= len(json_form)\n",
    "                elif len(json_to) > 1:\n",
    "                    json_from *= len(json_to)\n",
    "          \n",
    "                for froms[i], tos[i] in zip(json_from, json_to):\n",
    "\n",
    "                    count += 1\n",
    "                    i += 1\n",
    "                    if count >= max_edges:\n",
    "                        break\n",
    "                    if i%n == 0:\n",
    "                        conn.upsertEdges(from_name, edge_name, to_name, list(zip(froms, tos)))\n",
    "                        i = 0\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to restart the kernal before this one (keyboard shortcut 0,0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded local dev copy of autoTigerGraph!\n"
     ]
    }
   ],
   "source": [
    "import autoTigerGraph as atg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:14240\n"
     ]
    }
   ],
   "source": [
    "server = 'http://localhost'\n",
    "print(server+':14240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg\n",
    "\n",
    "conn = tg.TigerGraphConnection(host=server, graphname='yelp')\n",
    "shell = tg.Gsql(conn , certNeeded=False)\n",
    "\n",
    "shell.jarLocation='/home/ubuntu/tigergraph/app/3.0.0/dev/gdk/gsql/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\n",
      "---- Global vertices, edges, and all graphs\n",
      "Vertex Types: \n",
      "  - VERTEX Business(PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "  - Graph yelp(Business:v)\n",
      "Jobs: \n",
      "\n",
      "\n",
      "JSON API version: v2\n",
      "Syntax version: v1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql('ls', options=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\n",
      "Dropping all, about 1 minute ...\n",
      "Abort all active loading jobs\n",
      "Try to abort all loading jobs on graph yelp, it may take a while ...\n",
      "[ABORT_SUCCESS] No active Loading Job to abort.\n",
      "Resetting GPE...\n",
      "Successfully reset GPE\n",
      "Stopping GPE GSE\n",
      "Successfully stopped GPE GSE in 8.037 seconds\n",
      "Clearing graph store...\n",
      "Successfully cleared graph store\n",
      "Everything is dropped.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql('drop all', options=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\n",
      "---- Global vertices, edges, and all graphs\n",
      "Vertex Types: \n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "Jobs: \n",
      "\n",
      "\n",
      "JSON API version: v2\n",
      "Syntax version: v1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql('ls', options=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create schema and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\n",
      "Stopping GPE GSE RESTPP\n",
      "Successfully stopped GPE GSE RESTPP in 0.005 seconds\n",
      "Starting GPE GSE RESTPP\n",
      "Successfully started GPE GSE RESTPP in 0.076 seconds\n",
      "The graph yelp is created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql('create graph yelp (*)', options=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and upsert Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'business_id': 'f9NumwFMBDn751xgFiRbNA',\n",
       "  'name': 'The Range At Lake Norman',\n",
       "  'address': '10913 Bailey Rd',\n",
       "  'city': 'Cornelius',\n",
       "  'state': 'NC',\n",
       "  'postal_code': '28031',\n",
       "  'latitude': 35.4627242,\n",
       "  'longitude': -80.8526119,\n",
       "  'stars': 3.5,\n",
       "  'review_count': 36,\n",
       "  'is_open': 1,\n",
       "  'attributes': {'BusinessAcceptsCreditCards': 'True',\n",
       "   'BikeParking': 'True',\n",
       "   'GoodForKids': 'False',\n",
       "   'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\",\n",
       "   'ByAppointmentOnly': 'False',\n",
       "   'RestaurantsPriceRange2': '3'},\n",
       "  'categories': 'Active Life, Gun/Rifle Ranges, Guns & Ammo, Shopping',\n",
       "  'hours': {'Monday': '10:0-18:0',\n",
       "   'Tuesday': '11:0-20:0',\n",
       "   'Wednesday': '10:0-18:0',\n",
       "   'Thursday': '11:0-20:0',\n",
       "   'Friday': '11:0-20:0',\n",
       "   'Saturday': '11:0-20:0',\n",
       "   'Sunday': '13:0-18:0'}},\n",
       " [(0, 'business_id', 'str'),\n",
       "  (1, 'name', 'str'),\n",
       "  (2, 'address', 'str'),\n",
       "  (3, 'city', 'str'),\n",
       "  (4, 'state', 'str'),\n",
       "  (5, 'postal_code', 'str'),\n",
       "  (6, 'latitude', 'float'),\n",
       "  (7, 'longitude', 'float'),\n",
       "  (8, 'stars', 'float'),\n",
       "  (9, 'review_count', 'int'),\n",
       "  (10, 'is_open', 'int'),\n",
       "  (11, 'attributes', 'dict'),\n",
       "  (12, 'categories', 'str'),\n",
       "  (13, 'hours', 'dict')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'yelp_academic_dataset_business.json'\n",
    "vertex_name = 'Business'\n",
    "primary_id = 'business_id'\n",
    "\n",
    "json_object, fields = atg.get_first(filename)\n",
    "json_object, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE VERTEX Business (PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create = atg.vertex_from_json(json_object=json_object, vertex_name=vertex_name)\n",
    "create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\n",
      "The graph yelp is dropped.\n",
      "The vertex type Business is dropped.\n",
      "The vertex type Business is created.\n",
      "The graph yelp is created.\n",
      "---- Graph yelp\n",
      "Vertex Types: \n",
      "  - VERTEX User(PRIMARY_ID user_id STRING, name STRING, review_count INT, yelping_since STRING, useful INT, funny INT, cool INT, elite STRING, friends STRING, fans INT, average_stars DOUBLE, compliment_hot INT, compliment_more INT, compliment_profile INT, compliment_cute INT, compliment_list INT, compliment_note INT, compliment_plain INT, compliment_cool INT, compliment_funny INT, compliment_writer INT, compliment_photos INT) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "  - VERTEX Business(PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "  - Graph yelp(User:v, Business:v)\n",
      "Jobs: \n",
      "Queries: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql(\n",
    "'''\n",
    "drop graph yelp\n",
    "drop vertex {}\n",
    "{}\n",
    "create graph yelp (*)\n",
    "ls\n",
    "'''.format(vertex_name, create)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.upsert_json_vertices(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                      primary_id=primary_id, batch_size=10000, max_verts = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 10, 'v_type': 'Business'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell.gsql('select count(*) from {}'.format(vertex_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209393"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.upsert_json_vertices(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                      primary_id=primary_id, batch_size=10000, max_verts = 10**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 209393, 'v_type': 'Business'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell.gsql('select count(*) from {}'.format(vertex_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and upsert User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'user_id': 'ntlvfPzc8eglqvk92iDIAw',\n",
       "  'name': 'Rafael',\n",
       "  'review_count': 553,\n",
       "  'yelping_since': '2007-07-06 03:27:11',\n",
       "  'useful': 628,\n",
       "  'funny': 225,\n",
       "  'cool': 227,\n",
       "  'elite': '',\n",
       "  'friends': 'oeMvJh94PiGQnx_6GlndPQ, wm1z1PaJKvHgSDRKfwhfDg, IkRib6Xs91PPW7pon7VVig, A8Aq8f0-XvLBcyMk2GJdJQ, eEZM1kogR7eL4GOBZyPvBA, e1o1LN7ez5ckCpQeAab4iw, _HrJVzFaRFUhPva8cwBjpQ, pZeGZGzX-ROT_D5lam5uNg, 0S6EI51ej5J7dgYz3-O0lA, woDt8raW-AorxQM_tIE2eA, hWUnSE5gKXNe7bDc8uAG9A, c_3LDSO2RHwZ94_Q6j_O7w, -uv1wDiaplY6eXXS0VwQiA, QFjqxXn3acDC7hckFGUKMg, ErOqapICmHPTN8YobZIcfQ, mJLRvqLOKhqEdkgt9iEaCQ, VKX7jlScJSA-ja5hYRw12Q, ijIC9w5PRcj3dWVlanjZeg, CIZGlEw-Bp0rmkP8M6yQ9Q, OC6fT5WZ8EU7tEVJ3bzPBQ, UZSDGTDpycDzrlfUlyw2dQ, deL6e_z9xqZTIODKqnvRXQ, 5mG2ENw2PylIWElqHSMGqg, Uh5Kug2fvDd51RYmsNZkGg, 4dI4uoShugD9z84fYupelQ, EQpFHqGT9Tk6YSwORTtwpg, o4EGL2-ICGmRJzJ3GxB-vw, s8gK7sdVzJcYKcPv2dkZXw, vOYVZgb_GVe-kdtjQwSUHw, wBbjgHsrKr7BsPBrQwJf2w, p59u2EC_qcmCmLeX1jCi5Q, VSAZI1eHDrOPRWMK4Q2DIQ, efMfeI_dkhpeGykaRJqxfQ, x6qYcQ8_i0mMDzSLsFCbZg, K_zSmtNGw1fu-vmxyTVfCQ, 5IM6YPQCK-NABkXmHhlRGQ, U_w8ZMD26vnkeeS1sD7s4Q, AbfS_oXF8H6HJb5jFqhrLw, hbcjX4_D4KIfonNnwrH-cg, UKf66_MPz0zHCP70mF6p1g, hK2gYbxZRTqcqlSiQQcrtQ, 2Q45w_Twx_T9dXqlE16xtQ, BwRn8qcKSeA77HLaOTbfiQ, jouOn4VS_DtFPtMR2w8VDA, ESteyJabbfvqas6CEDs3pQ',\n",
       "  'fans': 14,\n",
       "  'average_stars': 3.57,\n",
       "  'compliment_hot': 3,\n",
       "  'compliment_more': 2,\n",
       "  'compliment_profile': 1,\n",
       "  'compliment_cute': 0,\n",
       "  'compliment_list': 1,\n",
       "  'compliment_note': 11,\n",
       "  'compliment_plain': 15,\n",
       "  'compliment_cool': 22,\n",
       "  'compliment_funny': 22,\n",
       "  'compliment_writer': 10,\n",
       "  'compliment_photos': 0},\n",
       " [(0, 'user_id', 'str'),\n",
       "  (1, 'name', 'str'),\n",
       "  (2, 'review_count', 'int'),\n",
       "  (3, 'yelping_since', 'str'),\n",
       "  (4, 'useful', 'int'),\n",
       "  (5, 'funny', 'int'),\n",
       "  (6, 'cool', 'int'),\n",
       "  (7, 'elite', 'str'),\n",
       "  (8, 'friends', 'str'),\n",
       "  (9, 'fans', 'int'),\n",
       "  (10, 'average_stars', 'float'),\n",
       "  (11, 'compliment_hot', 'int'),\n",
       "  (12, 'compliment_more', 'int'),\n",
       "  (13, 'compliment_profile', 'int'),\n",
       "  (14, 'compliment_cute', 'int'),\n",
       "  (15, 'compliment_list', 'int'),\n",
       "  (16, 'compliment_note', 'int'),\n",
       "  (17, 'compliment_plain', 'int'),\n",
       "  (18, 'compliment_cool', 'int'),\n",
       "  (19, 'compliment_funny', 'int'),\n",
       "  (20, 'compliment_writer', 'int'),\n",
       "  (21, 'compliment_photos', 'int')])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'yelp_academic_dataset_user.json'\n",
    "vertex_name = 'User'\n",
    "primary_id = 'user_id'\n",
    "\n",
    "json_object, fields = atg.get_first(filename)\n",
    "json_object, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE VERTEX User (PRIMARY_ID user_id STRING, name STRING, review_count INT, yelping_since STRING, useful INT, funny INT, cool INT, elite STRING, friends STRING, fans INT, average_stars DOUBLE, compliment_hot INT, compliment_more INT, compliment_profile INT, compliment_cute INT, compliment_list INT, compliment_note INT, compliment_plain INT, compliment_cool INT, compliment_funny INT, compliment_writer INT, compliment_photos INT)'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create = atg.vertex_from_json(json_object=json_object, vertex_name=vertex_name)\n",
    "create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\n",
      "The graph yelp is dropped.\n",
      "The vertex type User is dropped.\n",
      "The vertex type User is created.\n",
      "The graph yelp is created.\n",
      "---- Graph yelp\n",
      "Vertex Types: \n",
      "  - VERTEX Business(PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "  - VERTEX User(PRIMARY_ID user_id STRING, name STRING, review_count INT, yelping_since STRING, useful INT, funny INT, cool INT, elite STRING, friends STRING, fans INT, average_stars DOUBLE, compliment_hot INT, compliment_more INT, compliment_profile INT, compliment_cute INT, compliment_list INT, compliment_note INT, compliment_plain INT, compliment_cool INT, compliment_funny INT, compliment_writer INT, compliment_photos INT) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "  - Graph yelp(Business:v, User:v)\n",
      "Jobs: \n",
      "Queries: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql(\n",
    "'''\n",
    "drop graph yelp\n",
    "drop vertex {}\n",
    "{}\n",
    "create graph yelp (*)\n",
    "ls\n",
    "'''.format(vertex_name, create)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.upsert_json_vertices(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                      primary_id=primary_id, batch_size=10000, max_verts = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 10, 'v_type': 'User'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell.gsql('select count(*) from {}'.format(vertex_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1968703"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.upsert_json_vertices(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                      primary_id=primary_id, batch_size=10000, max_verts = 10**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 1968703, 'v_type': 'User'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell.gsql('select count(*) from {}'.format(vertex_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
